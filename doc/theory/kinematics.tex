\section{Kinematics}
\label{ch:kinematics}

What is captured by the camera, the camera footprint, when the camera is fixed to the aircraft body is dependent of the position and the attitude angles of the aircraft. In this section a model for calculating the camera footprint on the ground assuming flat earth will be presented, as well as the necessary UAV states for this thesis.


\subsection{UAV States}

The position of the UAV will be given using the North East Down (NED) coordinate frame, denoted $\{n\}$:

\begin{equation}
	\mathbf{p}_{b/n}^n =
	\begin{bmatrix}
		N \\ E \\ D
	\end{bmatrix}
	=
	\begin{bmatrix}
		x_n \\ y_n \\ z_n
	\end{bmatrix},
\end{equation}

with the corresponding velocities

\begin{equation}
	\mathbf{V}^b_g =
	\begin{bmatrix}
		u \\ v \\ w
	\end{bmatrix}.
\end{equation}

The attitude of the UAV will be given as Euler-angles:

\begin{equation}
	\bm{\Theta}_{nb} =
	\begin{bmatrix}
		\phi \\ \theta \\ \psi
	\end{bmatrix}	
\end{equation}

with corresponding angular velocities:

\begin{equation}
	\dot{\bm{\Theta}}_{nb} =
	\begin{bmatrix}
		p \\ q \\ r
	\end{bmatrix}.
\end{equation}


\subsection{Wind and Airspeed}
Wind will be introduced to the vehicle in order to test how the system withstands disturbances. Since the camera footprint is dependent only on the attitude angles of the aircraft and not the course of the aircraft, the wind will only affect the navigation of the UAV. Wind speed is given in the $\{n\}$ frame as \cite{uavBEARD}

\begin{equation}
	\mathbf{V}^n_w =
	\begin{bmatrix}
		w_n \\ w_e \\ w_d
	\end{bmatrix},
\end{equation}

and the air speed $\mathbf{V}_a$ of the aircraft is given by the wind speed $\mathbf{V}_w$ and ground speed $\mathbf{V}_g$ as

\begin{equation}
\begin{split}
	\mathbf{V}_a & = \mathbf{V}_g - \mathbf{V}_w\\
	\begin{bmatrix}
		u_r \\ v_r \\ w_r
	\end{bmatrix}
	& =
	\begin{bmatrix}
		u \\ v \\ w
	\end{bmatrix}
	- \mathbf{R}_n^b
	\begin{bmatrix}
		w_n \\ w_e \\ w_d
	\end{bmatrix}
\end{split}
\end{equation}

where $\mathbf{R}_n^b$ is the rotation matrix between the NED frame $\{n\}$ and the body frame $\{b\}$. 

%% Is the last part really needed?

When in the presence of wind, the heading of the UAV isn't necessarily the direction that the UAV is moving. Wind will introduce a crab angle $\chi_c$ that together with the heading $\psi$ gives the course angle $\chi$:

\begin{equation}
	\chi = \psi + \chi_c.
\end{equation}


\subsection{Camera Footprint}

The camera footprint is coupled with all of the three angles given in $\bm{\Theta}$. The position of the camera footprint will be calculated using forward kinematics, and the "SITUATION" is shown in figure \ref{fig:footprint_centre}.

\begin{figure}
	\import{/}{kinematics_footprint_figure.tex}
	\caption{Illustration of how the aircraft attitude influence the camera position.}
	\label{fig:footprint_centre}
\end{figure}

\subsubsection{Centre Position}

The attitude of the UAV is given in the body frame $\{b\}$ and the height $z_n$ is given in the NED frame $\{n\}$, and the model assumes flat earth. The position of the footprint centre point $\mathbf{c}_b^b$ in the body frame $\{b\}$ is expressed as the geometric (???) distance from the UAV position to the footprint centre point:

\begin{equation}
	\label{eq:camera_position_body}
	\mathbf{c}_b^b =
	\begin{bmatrix}
		c_{x/b}^b \\ c_{y/b}^b
	\end{bmatrix}
	=
	\begin{bmatrix}
		z_n tan(\theta) \\ z_n tan(\phi)
	\end{bmatrix}.
\end{equation}

The coordinates of the camera position in $\{n\}$ can be found by rotating the point $\mathbf{c}_b^b$ with respect to the aircraft heading $\psi$, and by translating the rotated point to the aircrafts position in the $\{n\}$ frame. The rotation matrix for rotating with respect to the heading is given as

\begin{equation}
	\mathbf{R}_{z,\psi} =
	\begin{bmatrix}
		cos(\psi) & -sin(\psi) \\
		sin(\psi) & cos(\psi)
	\end{bmatrix}.
\end{equation}

The final expression for the camera footprint centre position $\mathbf{c}^n$ in the $\{n\}$ frame then becomes:

\begin{equation}
\label{eq:camera_position_ned}
\begin{split}
	\mathbf{c}^n & = \mathbf{p} + \mathbf{R}_{z,\psi} \mathbf{c}_b^b \\
	& =
	\begin{bmatrix}
		x_n \\ y_n
	\end{bmatrix}
	+ \mathbf{R}_{z,\psi}
	\begin{bmatrix}
		x_{x/b}^b \\ c_{y/b}^b
	\end{bmatrix}
\end{split}
\end{equation}


\subsubsection{Edge Points}

A hyperspectral pushbroom sensor captures images in a line, and the centre point of the camera footprint does not express the entire area that is captured by the sensor. The edge points of the camera footprint are calculated with respect to the sensor's field of view, as shown in figure \ref{fig:kinematics_edge_points}. These points $\mathbf{e}$ can be found by altering \ref{eq:camera_position_body}:

\begin{equation}
	\mathbf{e}_{1,b}^b =
	\begin{bmatrix}
		z_n tan(\theta) \\ z_n tan(\phi + \sigma)
	\end{bmatrix}
	, \hspace{5pt}
	\mathbf{e}_{2,b}^b =
	\begin{bmatrix}
		z_n tan(\theta) \\ z_n tan(\phi - \sigma)
	\end{bmatrix}.
\end{equation}

\begin{figure}
	\import{/}{kinematic_edge_points_figure.tex}
	\caption{Illustration of how the field of view for a pushbroom sensor is calculated.}
	\label{fig:kinematics_edge_points}
\end{figure}

The steps for writing the edge points $\mathbf{e}$ in the $\{n\}$ is similar as in equation \ref{eq:camera_position_ned}:

\begin{equation}
	\mathbf{e}^n = \mathbf{p} + \mathbf{R}_{z,\psi} \mathbf{e}_b^b.
\end{equation}