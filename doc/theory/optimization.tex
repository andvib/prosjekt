\chapter{Model Predictive Control}
\label{ch:optimization}

Model Predictive Control (MPC) is a term used to describe control methods that uses knowledge about the process to calculate the future control inputs to the system in order to follow a reference trajectory \cite{mpcCAMACHO}. In this chapter the equations for an \textit{offline intervalwise MPC} that seeks to minimize the distance between the camera centre point and the ground path that is to be observed will be given. A linear state space-model for the UAV will be used to predict the future states and control inputs.


\section{MPC Method}

The MPC strategy can be broken down into three tasks \cite{mpcCAMACHO}:

\begin{enumerate}
	\item Predict the future outputs of the process for the given prediction horizon using past inputs to the process and the past measured states of the process, and by using the future control signals.
	\item Optimize an objective function in order to determine the future control signals that follows a given reference trajectory as closely as possible.
	\item Apply the optimal control signals to the process, and measure the resulting output so that it may be used to calculate the next prediction horizon in the first task.
\end{enumerate}

In short MPC problems are made up of three elements \cite{mpcCAMACHO}: Prediction model, objective function and the control law. The prediction model represents the model of the process that is to be controlled, and will in this case consist of the differential equations for the states of the UAV. The objective function is the function that is to be minimized by the optimization algorithm, in this case this will be the distance from the camera centre point to the desired ground path together with some of the UAV states that will give a stable flight. The objective function represents the reference trajectory that the UAV is to follow. The control law introduces constraints on the problem, reducing the number of feasible solutions. These constraints can be put on either the states or the control inputs for the UAV.

A common mathematical formulation of the three elements that make up the optimization problem is shown in \ref{eq:optimization_formulation} \cite{nocedalOPTIMIZATION}. $f(x)$ represents the objective function that is subject to equality and inequality constraints respectively. The equality constraints are used to represent the UAV model, while the inequality constraints represent the constraints used for the control law. A MPC differ from other optimization problems mostly in the objective function, which will be described in detail chapter \ref{ch:objective_function}.

\begin{equation}
	\label{eq:optimization_formulation}
	\begin{array}{rrclcl}
		\displaystyle \min_{x \in R^n} & \multicolumn{3}{l}{f(x)} \\
		\textrm{s.t}
		& c_i(x) = 0, i \in \epsilon, \\
		& c_i(x) \geq 0, i \in I.
	\end{array}
\end{equation}


\section{Offline Intervalwise MPC}

The control problem in this thesis will be solved by using an offline intervalwise MPC to generate an optimal path that will reduce the image error when using a fixed camera to survey a ground track. The generated path is intended to be tracked by the autopilot on the actual UAV that will perform the survey, with th eintention of optimally surveying the ground path.

\subsection{Offline MPC} 

An \textit{offline MPC} means that the initial state of the MPC is not a measurement of the UAV states, but rather the result of a simulation of the UAV. This means that the result from the prediction model used in the MPC will act as the physical system, and the outputs of the model will be fed back as inputs to the MPC for every iteration. The equations of the offline MPC are the same as the ones for the online version.

Rawlings \& Mayne \cite{mpcMAYNE} refers to this kind of problem as a \textit{deterministic problem} since there is no uncertainty in the system. A feedback loop in this kind of system is also not needed in principle, since it does not present any new information. They also state that an MPC action for a deterministic system is the same as the action from a \textit{receding horizon control law} (RHC), which is another kind of predictive control.

\subsection{Intervalwise MPC}

Altough the feedback is not needed to give new information, it eases the computational load of the control problem as optimizing the path over a long time horizon leads to a very complicated problem. For this reason a \textit{intervalwise MPC} will be used. The term intervalwise has been introduced by Kwon \& Han \cite{rhcKWON} to describe a type of receding horizon controller that implements the same strategy.

Commonly a MPC is used to optimize the model over a given \textit{horizon}, where the initial states are given. After the optimization has finished the first timestep of the optimization is returned and applied to the system, before a measurement of the system is performed. The new measurements are given as initial states for the next horizon, and so on.

The principle is the same for an intervalwise MPC. However, instead of only returning the first timestep an \textit{interval} of timesteps are returned, and the last timestep of the interval is used as intial states for the next optimization horizon. This way the number of MPC iterations is reduced, and the increased complexity by having long optimization horizons is avoided. Figure \ref{fig:opt_fig} shows how timesteps, intervals and horizons relate to each other.

\begin{figure}
	\import{/}{opt_fig.tex}
	\caption{The figure shows how the path is divided into sections and horizons when using the intervalwise MPC.}
	\label{fig:opt_fig}
\end{figure}


\section{Objective Function}
\label{ch:objective_function}

The main objective of the MPC developed in this thesis is to minimize the cross track error between the centre point of the camera footpring and the ground path that is to be observed. This, together with other objectives, will be defined in the objective function of the optimization problem. In this section a way of formulating the objective function, least-squares, will be described, and how it can expressed to function as a MPC.


\subsection{Least-Squares Problem}

In many applications the objective function is formulated as a least-square (LSQ) problem. LSQ is a form of regression where the distance from a certain point to a known model is measured [source]. In this case the known model is the reference signals and the distance between the current states and the reference signal is calculated by the LSQ. The general mathematical formulation for LSQ is \cite{nocedalOPTIMIZATION}:

\begin{equation}
	\label{eq:lsq}
	f(x) = \frac{1}{2} \sum_{j=1}^m r_j^2(x).
\end{equation}

In equation \ref{eq:lsq} $r_j$ is called the residual function, the distance between the point and the model. In relation to the MPC, the residual function is what the MPC seeks to minimize. The residual function is minimized by finding the parameters $x$ that minmize the residual function $r$.

\subsection{MPC Objective Function}

The objective function is where the goal of the optimization is expressed, together with the optimization horizon of the problem. Typical goals of the optimization is to follow a predefined trajectory or reference signal while reducing the control inputs used. This can be expressed as follows \cite{mpcCAMACHO}:

\begin{equation}
	\label{eq:mpc_cost}
	J(N_1, N_2, N_3) = \sum_{j=N_1}^{N_2} \delta(j)[\hat{y}(t+j|t)-w(t+j)]^2 + 
	\sum_{j=1}^{N_u}\lambda(j)[\Delta u(t+j-1)]^2.
\end{equation}

The first term of equation \ref{eq:mpc_cost} represents the costs from the states of the model, and the second term represents the cost of the control effort. In the first term $\hat{y}$ is the value of the prediction model, which is compared to the desired trajectory $w$. In the second term the changes in control $\Delta u$ is expressed. The changes in control is used instead of the value of the control signal itself, since the steady state of the control signal may not be zero. $\delta$ and $\lambda$ are weighting variables which offers a way of tuning the MPC. The three different $N$ coefficients defines the horizon over which the states and the control effort should be optimized. The optimization horizon for states and control effort can be different, but they will stay the same for this problem.


\section{Problem Definition}

\begin{equation}
\label{eq:opt}
	\begin{array}{rrclcl}
		\displaystyle \min_{\mathbf{z}} & \multicolumn{3}{l}{\mathbf{J}_k = \frac{1}{2} \sum_{i=k}^{k+L} [\mathbf{h}(\mathbf{z}_i)^\intercal \mathbf{Q}\mathbf{h}(\mathbf{z}_i)] + \frac{1}{2}\sum_{i=k}^{k=L}[\mathbf{u}_i^\intercal \mathbf{R}\mathbf{u}_i]}\\
		\textrm{s.t}
		& \mathbf{x}^{low} \leq & \mathbf{x}_i & \leq \mathbf{x}^{high} \\
		& \mathbf{u}^{low} \leq & \mathbf{u}_i & \leq \mathbf{u}^{high} \\
		& \displaystyle \mathbf{\dot{x}} & = & f(\mathbf{x},\mathbf{u})
	\end{array}
\end{equation}

The equations for the full optimization problem is shown in equation \ref{eq:opt}. The objective function uses the same setup as shown in equation \ref{eq:mpc_cost}, but on matrix form. Each of the three components of the problem definition will be described in detail in the following sections.


\subsection{Objective Function}

\begin{equation}
	\mathbf{J}_k = \frac{1}{2} \sum_{i=k}^{k+L} [\mathbf{h}(\mathbf{z}_i)^\intercal \mathbf{Q}\mathbf{h}(\mathbf{z}_i)] + \frac{1}{2}\sum_{i=k}^{k=L}[\mathbf{u}_i^\intercal \mathbf{R}\mathbf{u}_i]
\end{equation}

The first term of the objective function calculates the distance between the UAV states and the reference trajectory. The vector $\mathbf{z}$ is the optimization vector that contains the UAV states that will be included in the optimization problem and $\mathbf{Q}$ is the weighting matrix. The states included in the optimization vector are

\begin{equation}
	\mathbf{z} =
	\begin{bmatrix}
		p_N \hspace{5pt} p_E \hspace{5pt} h \hspace{5pt} u
	\end{bmatrix} ^\intercal .
\end{equation}

The function $\mathbf{h}$ is where the distance between the reference signal and the UAV states is calculated. For the the north-east position of the camera centre point is compared to the observation path, while the height $h$ and speed $u$ is compared to a constant reference signal $h_d$ and $u_d$ respectively:

\begin{equation}
	\mathbf{h} =
	\begin{bmatrix}
		p_N - {p_N}_d \\
		p_E - {p_E}_d \\
		h - h_d \\
		u - u_d
	\end{bmatrix}.
\end{equation}

In order to reduce the control effort for the optimization problem the rate of change of the control inputs $d\mathbf{u}$ will be minimized. Since all the control rates is to be compared to zero no function is needed. The matrix $\mathbf{R}$ is the weighting matrix. The vector $u$ contains of the four control rates:

\begin{equation}
	\mathbf{u} = 
	\begin{bmatrix}
		d\delta_e \hspace{5pt} d\delta_a \hspace{5pt} d\delta_r \hspace{5pt} d\delta_t
	\end{bmatrix} ^\intercal .
\end{equation}


\subsection{Prediction Model}

The linear decoupled 12 DOF UAV model presented by Beard \& McLain \cite{uavBEARD} will be implemented. This model is associated with the following states and control inputs:

\begin{subequations}
\begin{equation}
	\mathbf{x} =
	\begin{bmatrix}
		p_N \hspace{5pt} p_E \hspace{5pt} h \hspace{5pt}
		u \hspace{5pt} v \hspace{5pt} w \hspace{5pt}
		\phi \hspace{5pt} \theta \hspace{5pt} \psi \hspace{5pt}
		p \hspace{5pt} q \hspace{5pt} r
	\end{bmatrix}^T
\end{equation}
\begin{equation}
	\mathbf{u} =
	\begin{bmatrix}
		\delta_e \hspace{5pt} \delta_a \hspace{5pt} \delta_r \hspace{5pt} \delta_t
	\end{bmatrix}^T.
\end{equation}
\end{subequations}

The prediction model relates to the equality constraints of equation \ref{eq:optimization_formulation} in the form of differential equations. Based on the control inputs and current states, $\mathbf{\dot{x}}$ is calculated by the differential equation. The attitude angles will be expressed in Euler angles. Even though quaternions offer more efficient computations and no gimbal lock \cite{uavBEARD}, this optimization will be run on an offboard computer/offline so that computation capacity is not a big issue and the UAV is not going to undergo any extreme maneuvers so that a gimbal lock should never occur.


\subsection{Control Law}

The only physical constraints in this optimization problem is constraints on the control inputs, as shown in equation \ref{eq:control_constraint}. This inequality constraint ensures that the control surfaces of the UAV simulated in the optimization do not excede what the UAV is physically capable of.

\begin{equation}
	\label{eq:control_constraint}
	\mathbf{u}^{low} \leq \mathbf{u} \leq \mathbf{u}^{high}
\end{equation}
% Should maybe come from a source? Different formulation?